# LLM_Parser: Advanced LLM-Powered Knowledge Chatbot

**Showcase your expertise in Large Language Models, Retrieval-Augmented Generation (RAG), and modern AI product development.**

## üöÄ Project Overview

LLM_Parser is a robust, production-style Streamlit application that empowers users to:
- **Ingest knowledge** from both web URLs and uploaded documents (PDF, TXT, DOCX)
- **Build a scalable vector store** using OpenAI, LangChain, and FAISS
- **Chat with the knowledge base** using multi-turn, context-aware conversations
- **Attribute answers to sources** for transparency and trust
- **Select between top OpenAI models** (GPT-3.5, GPT-4)

## ‚ú® Key Features
- **Multi-source ingestion:** Add any number of URLs and upload files for knowledge extraction
- **Advanced RAG pipeline:** Combines OpenAI LLMs, LangChain, and FAISS for efficient, accurate retrieval
- **Multi-turn chat interface:** Natural, ongoing conversations with chat history
- **Source attribution:** See which URLs or files contributed to each answer
- **Model selection:** Choose between GPT-3.5 and GPT-4 for responses
- **Session management:** Clear/reset knowledge base and chat history with one click
- **Modern UI:** Built with Streamlit for a clean, interactive user experience

## üõ†Ô∏è How to Run
1. **Clone the repository:**
   ```bash
   git clone https://github.com/sahilhd/LLM_Parser.git
   cd LLM_Parser
   ```
2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
3. **Set your OpenAI API key:**
   ```bash
   export OPENAI_API_KEY=your-openai-api-key
   ```
4. **Start the app:**
   ```bash
   streamlit run main.py
   ```
5. **Use the sidebar to add URLs, upload documents, and build your knowledge base.**
6. **Chat with your knowledge base in the main window!**

## üéØ Why This Project Stands Out (For Recruiters)
- **Demonstrates real-world LLM product skills:** End-to-end pipeline from data ingestion to user-facing chat
- **Integrates state-of-the-art libraries:** OpenAI, LangChain, FAISS, Streamlit
- **Showcases advanced RAG techniques:** Not just Q&A, but multi-turn, source-attributed, context-aware chat
- **Production-ready patterns:** Persistent vector store, error handling, session management, and extensible design
- **User-centric design:** Clean UI, clear feedback, and robust controls

---

*Built for learning, demonstration, and as a portfolio centerpiece for LLM and AI product engineering roles.*
